{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to combine all of the WNV JSON files into a single JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "# Empty list for JSON data\n",
    "json_data = []\n",
    "\n",
    "# Loops through JSON files in data dir and extract the contents of each and append to the empty list declared above\n",
    "# Glob would would grab files randomly, using sorted to have glob pickup file sequentially. \n",
    "for file in sorted(glob.glob('./data/wnv/*.json')):\n",
    "    \n",
    "    # Open and read file in binary mode to keep data as is and not convert anything (e.g. new line, end of line) \n",
    "    with open(file, 'rb') as infile:\n",
    "        \n",
    "        # Append the currently open file to the json_data list\n",
    "        json_data.append(json.load(infile))\n",
    "\n",
    "# Output JSON data to new file \n",
    "with open('./data/wnv/output/wnv2003_2018.json', 'w') as outfile:\n",
    "    json.dump(json_data, outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the newly created JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = pd.read_json('./data/wnv/output/wnv2003_2018.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dead_bird</th>\n",
       "      <th>pool</th>\n",
       "      <th>sentinel</th>\n",
       "      <th>surveillance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[[-115.55991333277777, 32.79452379068916, El C...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[-0.0037874454854030003, 0.004151121647450000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[[-115.70874635314847, 32.760950501453685, See...</td>\n",
       "      <td>[[-115.70466298389093, 32.76097984589758, Seel...</td>\n",
       "      <td>[[0.00040120886695000003, -0.00237453044225900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>[[-115.70778129001854, 32.76645731969914, Seel...</td>\n",
       "      <td>[[-115.70380745397101, 32.76212619660325, Seel...</td>\n",
       "      <td>[[0.000582078219765, 0.002604673449621, Pico R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-117.06524547408917, 32.57587171177409, San ...</td>\n",
       "      <td>[[-115.70536399338327, 33.06352430738503, West...</td>\n",
       "      <td>[[-115.7063219308171, 32.765271649553355, Seel...</td>\n",
       "      <td>[[0.0042305860051320004, 0.001971813442978, Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-117.08130333018387, 32.64154680042579, Chul...</td>\n",
       "      <td>[[-117.03840702222823, 32.59563784834163, Chul...</td>\n",
       "      <td>[[-115.7048189736365, 32.75950529599969, Seele...</td>\n",
       "      <td>[[-0.004922821113662001, -0.004294370979541, C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           dead_bird  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [[-117.06524547408917, 32.57587171177409, San ...   \n",
       "4  [[-117.08130333018387, 32.64154680042579, Chul...   \n",
       "\n",
       "                                                pool  \\\n",
       "0  [[-115.55991333277777, 32.79452379068916, El C...   \n",
       "1  [[-115.70874635314847, 32.760950501453685, See...   \n",
       "2  [[-115.70778129001854, 32.76645731969914, Seel...   \n",
       "3  [[-115.70536399338327, 33.06352430738503, West...   \n",
       "4  [[-117.03840702222823, 32.59563784834163, Chul...   \n",
       "\n",
       "                                            sentinel  \\\n",
       "0                                                 []   \n",
       "1  [[-115.70466298389093, 32.76097984589758, Seel...   \n",
       "2  [[-115.70380745397101, 32.76212619660325, Seel...   \n",
       "3  [[-115.7063219308171, 32.765271649553355, Seel...   \n",
       "4  [[-115.7048189736365, 32.75950529599969, Seele...   \n",
       "\n",
       "                                        surveillance  \n",
       "0  [[-0.0037874454854030003, 0.004151121647450000...  \n",
       "1  [[0.00040120886695000003, -0.00237453044225900...  \n",
       "2  [[0.000582078219765, 0.002604673449621, Pico R...  \n",
       "3  [[0.0042305860051320004, 0.001971813442978, Un...  \n",
       "4  [[-0.004922821113662001, -0.004294370979541, C...  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the JSON without assigning to a dataframe instead.  Seems like it may be easier to work with it this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/wnv/output/wnv2003_2018.json') as f:\n",
    "    d = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign json objects to year variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_03 = d[0]\n",
    "year_04 = d[1]\n",
    "year_05 = d[2]\n",
    "year_06 = d[3]\n",
    "year_07 = d[4]\n",
    "year_08 = d[5]\n",
    "year_09 = d[6]\n",
    "year_10 = d[7]\n",
    "year_11 = d[8]\n",
    "year_12 = d[9]\n",
    "year_13 = d[10]\n",
    "year_14 = d[11]\n",
    "year_15 = d[12]\n",
    "year_16 = d[13]\n",
    "year_17 = d[14]\n",
    "year_18 = d[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign each specimen type (except surveillance) to a variable to create a dataframe if it has data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_03_pool = json_normalize(year_03, record_path='pool')\n",
    "\n",
    "year_04_sentinel = json_normalize(year_04, record_path='sentinel')\n",
    "year_04_pool = json_normalize(year_04, record_path='pool')\n",
    "\n",
    "year_05_sentinel = json_normalize(year_05, record_path='sentinel')\n",
    "year_05_pool = json_normalize(year_05, record_path='pool')\n",
    "\n",
    "year_06_sentinel = json_normalize(year_06, record_path='sentinel')\n",
    "year_06_dead_bird = json_normalize(year_06, record_path='dead_bird')\n",
    "year_06_pool = json_normalize(year_06, record_path='pool')\n",
    "\n",
    "year_07_sentinel = json_normalize(year_07, record_path='sentinel')\n",
    "year_07_dead_bird = json_normalize(year_07, record_path='dead_bird')\n",
    "year_07_pool = json_normalize(year_07, record_path='pool')\n",
    "\n",
    "year_08_sentinel = json_normalize(year_08, record_path='sentinel')\n",
    "year_08_dead_bird = json_normalize(year_08, record_path='dead_bird')\n",
    "year_08_pool = json_normalize(year_08, record_path='pool')\n",
    "\n",
    "year_09_sentinel = json_normalize(year_09, record_path='sentinel')\n",
    "year_09_dead_bird = json_normalize(year_09, record_path='dead_bird')\n",
    "year_09_pool = json_normalize(year_09, record_path='pool')\n",
    "\n",
    "year_10_sentinel = json_normalize(year_10, record_path='sentinel')\n",
    "year_10_dead_bird = json_normalize(year_10, record_path='dead_bird')\n",
    "year_10_pool = json_normalize(year_10, record_path='pool')\n",
    "\n",
    "year_11_sentinel = json_normalize(year_11, record_path='sentinel')\n",
    "year_11_dead_bird = json_normalize(year_11, record_path='dead_bird')\n",
    "year_11_pool = json_normalize(year_11, record_path='pool')\n",
    "\n",
    "year_12_sentinel = json_normalize(year_12, record_path='sentinel')\n",
    "year_12_dead_bird = json_normalize(year_12, record_path='dead_bird')\n",
    "year_12_pool = json_normalize(year_12, record_path='pool')\n",
    "\n",
    "year_13_sentinel = json_normalize(year_13, record_path='sentinel')\n",
    "year_13_dead_bird = json_normalize(year_13, record_path='dead_bird')\n",
    "year_13_pool = json_normalize(year_13, record_path='pool')\n",
    "\n",
    "year_14_sentinel = json_normalize(year_14, record_path='sentinel')\n",
    "year_14_dead_bird = json_normalize(year_14, record_path='dead_bird')\n",
    "year_14_pool = json_normalize(year_14, record_path='pool')\n",
    "\n",
    "year_15_sentinel = json_normalize(year_15, record_path='sentinel')\n",
    "year_15_dead_bird = json_normalize(year_15, record_path='dead_bird')\n",
    "year_15_pool = json_normalize(year_15, record_path='pool')\n",
    "\n",
    "year_16_sentinel = json_normalize(year_16, record_path='sentinel')\n",
    "year_16_dead_bird = json_normalize(year_16, record_path='dead_bird')\n",
    "year_16_pool = json_normalize(year_16, record_path='pool')\n",
    "\n",
    "year_17_sentinel = json_normalize(year_17, record_path='sentinel')\n",
    "year_17_dead_bird = json_normalize(year_17, record_path='dead_bird')\n",
    "year_17_pool = json_normalize(year_17, record_path='pool')\n",
    "\n",
    "year_18_sentinel = json_normalize(year_18, record_path='sentinel')\n",
    "year_18_dead_bird = json_normalize(year_18, record_path='dead_bird')\n",
    "year_18_pool = json_normalize(year_18, record_path='pool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to cleanup the resulting dataframes a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the function a dataframe to work with\n",
    "def df_cleanup(dataframes):\n",
    "    for pdf in dataframes:\n",
    "        \n",
    "        # Rename columns\n",
    "        pdf.rename(columns={0: 'lon', 1: 'lat', 2 : 'city', 3 : 'collections', 4 : 'virus', 5 : 'date'}, inplace=True)\n",
    "        \n",
    "        # Ensure all city names are capitalized\n",
    "        pdf['city'] = pdf['city'].str.title()\n",
    "        \n",
    "        # Round coordinates to 6 decimal places\n",
    "        pdf['lat'] = pdf['lat'].round(6)\n",
    "        pdf['lon'] = pdf['lon'].round(6)\n",
    "        \n",
    "        # Add a spectype column which will be populated later\n",
    "        pdf['spectype'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of our dataframes which will be passed to the df_cleanup function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dfs = [year_03_pool, \n",
    "            year_04_sentinel, \n",
    "            year_04_pool, \n",
    "            year_05_sentinel, \n",
    "            year_05_pool, \n",
    "            year_06_sentinel, \n",
    "            year_06_dead_bird, \n",
    "            year_06_pool, \n",
    "            year_07_sentinel, \n",
    "            year_07_dead_bird, \n",
    "            year_07_pool, \n",
    "            year_08_sentinel, \n",
    "            year_08_dead_bird, \n",
    "            year_08_pool, \n",
    "            year_09_sentinel, \n",
    "            year_09_dead_bird, \n",
    "            year_09_pool, \n",
    "            year_10_sentinel,\n",
    "            year_10_dead_bird, \n",
    "            year_10_pool, \n",
    "            year_11_sentinel,\n",
    "            year_11_dead_bird, \n",
    "            year_11_pool, \n",
    "            year_12_sentinel, \n",
    "            year_12_dead_bird, \n",
    "            year_12_pool, \n",
    "            year_13_sentinel, \n",
    "            year_13_dead_bird, \n",
    "            year_13_pool, \n",
    "            year_14_sentinel, \n",
    "            year_14_dead_bird, \n",
    "            year_14_pool, \n",
    "            year_15_sentinel, \n",
    "            year_15_dead_bird, \n",
    "            year_15_pool, \n",
    "            year_16_sentinel, \n",
    "            year_16_dead_bird, \n",
    "            year_16_pool, \n",
    "            year_17_sentinel, \n",
    "            year_17_dead_bird, \n",
    "            year_17_pool, \n",
    "            year_18_sentinel, \n",
    "            year_18_dead_bird, \n",
    "            year_18_pool\n",
    "           ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass our list of dataframes to *df_cleanup* to tidy things up a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanup(json_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the *spectype* column in the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_03_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_04_sentinel['spectype'] = 'Sentinel Chicken' \n",
    "year_04_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_05_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_05_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_06_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_06_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_06_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_07_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_07_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_07_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_08_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_08_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_08_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_09_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_09_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_09_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_10_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_10_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_10_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_11_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_11_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_11_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_12_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_12_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_12_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_13_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_13_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_13_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_14_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_14_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_14_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_15_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_15_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_15_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_16_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_16_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_16_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_17_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_17_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_17_pool['spectype'] = 'Mosquito Pool' \n",
    "\n",
    "year_18_sentinel['spectype'] = 'Sentinel Chicken'\n",
    "year_18_dead_bird['spectype'] = 'Dead Bird'\n",
    "year_18_pool['spectype'] = 'Mosquito Pool' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 746 entries, 0 to 745\n",
      "Data columns (total 7 columns):\n",
      "lon            746 non-null float64\n",
      "lat            746 non-null float64\n",
      "city           693 non-null object\n",
      "collections    746 non-null int64\n",
      "virus          746 non-null object\n",
      "date           746 non-null object\n",
      "spectype       746 non-null object\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 40.9+ KB\n"
     ]
    }
   ],
   "source": [
    "year_18_pool.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all our data frames and using `concat` since they all have the same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfs = pd.concat(json_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip out all the square brackets from the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     [[9-16-2003, 1]]\n",
       "1                                     [[7-16-2003, 1]]\n",
       "2                                     [[9-16-2003, 1]]\n",
       "3                      [[8-19-2003, 2], [9-2-2003, 2]]\n",
       "4    [[8-4-2003, 1], [8-19-2003, 2], [9-2-2003, 3],...\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take intial look\n",
    "merged_dfs['date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip out square brackets now\n",
    "merged_dfs['date'] = merged_dfs['date'].astype(str).str.replace(\"[\",\"\").str.replace(\"]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       '9-16-2003', 1\n",
       "1                                       '7-16-2003', 1\n",
       "2                                       '9-16-2003', 1\n",
       "3                        '8-19-2003', 2, '9-2-2003', 2\n",
       "4    '8-4-2003', 1, '8-19-2003', 2, '9-2-2003', 3, ...\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look after stripping out brackets\n",
    "merged_dfs['date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create a geojson from a dataframe.  Many thanks to [Geoff Boeing](https://geoffboeing.com/2015/10/exporting-python-data-geojson/) for his solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the function a dataframe, properties, and lat/lon\n",
    "def df_to_geojson(df, properties, lat='lat', lon='lon'):\n",
    "        \n",
    "        # Create a dictionary for our geojson which also includes a list for our features\n",
    "        geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "        \n",
    "        # Loop over our dataframe and begin populating fields that will create our GeoJSON. \n",
    "        # '_' is our dataframe index but we aren't going to use that anywhere else in the \n",
    "        for _, row in df.iterrows():\n",
    "            \n",
    "            # Create a dictionary for our features elements\n",
    "            feature = {'type':'Feature',\n",
    "                       'properties':{},\n",
    "                       'geometry':{'type':'Point',\n",
    "                                   'coordinates':[]}}\n",
    "            \n",
    "            # Pass our lat/lon from our dataframe to populate the geometry coordinates in our feature dictionary\n",
    "            feature['geometry']['coordinates'] = [row[lon],row[lat]]\n",
    "            \n",
    "            # Loop over the properties list we passed the function to populate the properties portion of our feature dictionary\n",
    "            for prop in properties:\n",
    "                feature['properties'][prop] = row[prop]\n",
    "            \n",
    "            # Add our newly populated features dictionary to the features list of our geojson dictonary\n",
    "            geojson['features'].append(feature)\n",
    "            \n",
    "        # Return our now fully poplulated geojson dictionary so we will be able to output to a GeoJSON    \n",
    "        return geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passed the merged dataframe to *df_to_geojson*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['city','collections','virus','date','spectype']\n",
    "wnv_geojson = df_to_geojson(merged_dfs,columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write *wnv_geojson* to an actual file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnv_geojson_output = './data/wnv/output/wnv2003_2018.geojson'\n",
    "with open(wnv_geojson_output, 'w') as output_file:\n",
    "    json.dump(wnv_geojson, output_file, indent=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
